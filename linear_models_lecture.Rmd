---
title: "p8105_linear_models"
author: "Jana Lee"
date: "11/7/2019"
output: html_document
---

## Setup
```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
set.seed(1)
```


## Lecture: Linear Regression
lm = linear model, continuous outcome variable
glm = generalized linear models, binary outcome

arguments include:
- formula: y~x1 + x2
- data

Outputs are kind of a mess, but we can use the broom package to clean it up.

### Fit a model:
```{r}
library(p8105.datasets)
set.seed(1)

data("nyc_airbnb")

# Qustion: Is it possible to predict price based on a couple of preditors?
# Initial data cleaning:
nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    boro = neighbourhood_group,
    neighborhood = neighbourhood) %>% 
  filter(boro != "Staten Island") %>% 
  select(price, stars, boro, neighborhood, room_type)
```

Fit the first linear model:
When you fit 4 categorical variables, it is going to organize this by alphabetical order. Bronx becomes our reference category.
Stars = if stars go up by 1-unit, airbnb increase 31.99 dollars
Boro_Brooklyn = if brooklyn goes up about 1-unit, airbnb increases 40.50 dollars
```{r}
fit = lm(price ~ stars + boro, data = nyc_airbnb)

# this is kind of helpful: summary
summary(fit)

#Another way of extracting results
summary(fit)$coef

# extract coefficients out
coef(fit)

fitted.values(fit)

#tidying results, changing the string variable to make it easier to read, and presenting this in a table
fit %>% 
  broom::tidy() %>%
  mutate(term = str_replace(term, "boro", "Boro:")) %>% 
  knitr::kable(digits = 3)

```


Looking at factors...
```{r}
# put categorical factors in order based on what is most common, which borough is more frequent?
nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(
    boro = fct_infreq(boro),
    room_type = fct_infreq(room_type)
  )
```


Refitting the last model, now that factors have been reordered:
```{r}
fit = lm(price ~ stars + boro, data = nyc_airbnb)

fit %>% 
  broom::tidy()
```


Extract this information: r-squared, p-value, df, etc.
```{r}
fit %>% 
  broom::glance()
```


### Diagnostic information:
-The `modelr` package can be used to add residuals and fitted values to a dataframe. This will add in the residuals.
```{r}
modelr::add_residuals(nyc_airbnb, fit) %>% 
  ggplot(aes(x = boro, y = resid)) + 
  geom_violin() +
  ylim(-500, 500)


nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = stars, y = resid)) + geom_point()
```

What is the predicted values this model gives?
```{r}
modelr::add_predictions(nyc_airbnb, fit)
```


### Hypothesis Testing (skipping this)
```{r}
fit_null = lm(price ~ stars + boro, data = nyc_airbnb)
fit_alt = lm(price ~ stars + boro + room_type, data = nyc_airbnb)

anova(fit_null, fit_alt) %>% 
  broom::tidy()
```
This works for nested models only. Comparing non-nested models requires other methods --> aka cross validation.

### Nesting Data
We’ll now turn our attention to fitting models to datasets nested within variables – meaning, essentially, that we’ll use nest to create a list column containing datasets and fit separate models to each. This is very different from fitting nested models, even though the terminology is similar.

In the airbnb data, we might think that star ratings and room type affects price differently in each borough. One way to allow this kind of effect modification is through interaction terms:
```{r}
fit_interaction = lm(price ~ stars * boro, data = nyc_airbnb)

fit_interaction %>% 
  broom::tidy()

# This is asking: what the effect of stars for each borough on the price of airbnb? If you're looking on airbnb rentals in manhattan, this is gonna matter how much you pay. But queens and bronx, it won't really matter.

fit_interaction = lm(price ~ stars * boro + room_type*boro, data = nyc_airbnb)
# We can look at the interaction of room_type as well! This model is very flexible. Different model for the effect of stars and the effect of borough / room type.
```

```{r}
nyc_airbnb %>% 
  filter(boro == "Brooklyn") %>% 
  lm(price ~ stars + room_type, data = .) %>% 
  broom::tidy()
```


Trying mapping instead. Alternatively, we can nest within boroughs and fit borough-specific models associating price with rating and room type:
```{r}
nyc_airbnb %>% 
  nest(data = -boro) %>% 
  mutate(
    models = map(.x = data, ~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(boro, results) %>% 
  unnest(results)
```

## Let's nest neighborhoods
```{r}
manhattan_airbnb =
  nyc_airbnb %>% 
  filter(boro == "Manhattan")

manhattan_nest_lm_res =
  manhattan_airbnb %>% 
  nest(data = -neighborhood) %>% 
  mutate(models = map(data, ~lm(price ~ stars + room_type, data = .x)),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest(models)
```


```{r}
manhattan_nest_lm_res %>% 
  filter(str_detect(term, "room_type")) %>% 
  ggplot(aes(x = neighborhood, y = estimate)) + 
  geom_point() + 
  facet_wrap(~term) + 
  theme(axis.text.x = element_text(angle = 80, hjust = 1))
```

Deep dive into NoHo room, where shared room is more expensive than private room:
```{r}
nyc_airbnb %>% 
  filter(neighborhood == "NoHo", room_type == "Shared room")
```


### Binary Outcomes
Using homicide dataset from Washington Post. We will use the unresolved murders in Baltimore, MD to illustrate logistic regression.

Need to specify family (binomial)

```{r}
baltimore_df = 
  read_csv("data/homicide-data.csv") %>% 
  filter(city == "Baltimore") %>% 
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")) %>% 
  select(resolved, victim_age, victim_race, victim_sex)
```

Fit a logistic regression for the binary "resolved" outcome and victim demographics as predictors. Uses glm function with the family specified to account for non-Gaussian outcome distribution.
```{r}
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 
```

Using logistic regression to get ORs:
```{r}
fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>%
  select(term, log_OR = estimate, OR, p.value) %>% 
  knitr::kable(digits = 3)
```

Compute fitted values to estimate the model summary
```{r}
baltimore_df %>% 
  modelr::add_predictions(fit_logistic) %>%
  mutate(fitted_prob = boot::inv.logit(pred))
```

In Baltimore, race disparities exist. Can map across all the cities in the datasets across all cities.





## Lecture: Cross-Validation
```{r}
library (tidyverse)
library(modelr)
library(mgcv)

set.seed(1)
```
mgcv::gam = go-to package for "additive models"

### Doing cross-validation by hand. Simulated example.
```{r}
nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )

nonlin_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + theme_bw()
```


training vs. testing datasets. Goal is to use the training data (black) to build candidate models and then see how those models predict in the testing data (red) 
```{r}
train_df = sample_n(nonlin_df, 80)
test_df = anti_join(nonlin_df, train_df, by = "id")

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = "red")
```


Fit 3 models of varying goodness
```{r}
linear_mod = lm(y ~ x, data = train_df)
smooth_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

Using the 3 models and testing that with the add_prediction area. How can I compare these different models that would confirm these?
```{r}
train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_point(aes(y = pred), color = "red")
```

Faceting these 3 models
```{r}
train_df %>% 
  gather_predictions(linear_mod, smooth_mod, wiggly_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_line(aes(y = pred), color = "red") +
  facet_wrap(~model)
```
Quick visual inspection shows us that the linear model is too simple, the standard gam is pretty good and the wiggy gam is too complex.

Next step: Computing root mean squared errors (RMSEs) for each model. Always pick the model that will do better on the testing dataset
```{r}
rmse(linear_mod, test_df)
rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)
```
We see that both non-linear models work better than the linear model. But we need to understand if the model is stable, so we need t o iterate this whole process.

### Cross Validation in model r
80-20 is the default for crossv_mc
```{r}
cv_df = 
  crossv_mc(nonlin_df, 100) 
```


```{r}
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

Iterate this for the following models
map1 = just gives you one
map2 = gives you first column and second column (models, datasets)
```{r}
cv_results = 
  cv_df %>% 
  mutate(linear_mod  = map(train, ~lm(y ~ x, data = .x)),
         smooth_mod  = map(train, ~mgcv::gam(y ~ s(x), data = .x)),
         wiggly_mod  = map(train, ~mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))) %>% 
  mutate(rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
         rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)),
         rmse_wiggly = map2_dbl(wiggly_mod, test, ~rmse(model = .x, data = .y)))
```

Data Manipulation
- RMSE is above. Going to pick the smooth model bc it has the lowest RMSE
```{r}
cv_results %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Here, iteration is helpful. We get a sense of the variance in prediction error and can compare prediction error distributions across methods. The smooth is a clear winner!

### Example with Child Growth
```{r}
child_growth = read_csv("./data/nepalese_children.csv")
```

We think that non-linearity might be happening here.
```{r}
child_growth %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5)
```
Plot suggests some non-linearity, especially at the low end of the weight distirbution.

Add code to do change point term
```{r}
child_growth =
  child_growth %>% 
  mutate(weight_cp = (weight > 7) * (weight - 7))
```

Checking goodness of fit
```{r}
linear_mod = lm(armc ~ weight, data = child_growth)
pwl_mod = lm(armc ~ weight + weight_cp, data = child_growth)
smooth_mod = gam(armc ~ s(weight), data = child_growth)

child_growth %>% 
  gather_predictions(linear_mod, pwl_mod, smooth_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```
From the facet, it's not clear which is best. But the piecewise and non-linear models are pretty similar.

Convert the resample obsjects to dataframes
```{r}
cv_df =
  crossv_mc(child_growth, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

Use mutate, map, and map2 to fit models to training data and obtain RMSEs for testing data
```{r}
cv_df = 
  cv_df %>% 
  mutate(linear_mod  = map(train, ~lm(armc ~ weight, data = .x)),
         pwl_mod = map(train, ~lm(armc ~ weight + weight_cp, data = .x)),
         smooth_mod = map(train, ~gam(armc ~ s(weight), data = as_tibble(.x)))) %>% 
  mutate(rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
         rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
         rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)))
```

Plot the prediction error distribution for each candidate model
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
There's some improvement in predictive accuracy gained by allowing non-linearity. Between the two, go with piecewise and gam fits because they are easier to interpret.
